{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models as sm\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    set_random_seed(seed)\n",
    "\n",
    "seed = 0\n",
    "seed_everything(seed)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# prevent cudnn InternalError\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "# config = K.tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "submission = pd.read_csv('input/sample_submission.csv')\n",
    "print('Number of train samples:', train.shape[0])\n",
    "print('Number of test samples:', submission.shape[0])\n",
    "\n",
    "# Preprocecss data\n",
    "train['image'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "submission['image'] = submission['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test = pd.DataFrame(submission['image'].unique(), columns=['image'])\n",
    "\n",
    "display(train.head())\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(1400, 2100)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Has Mask'] = ~train['EncodedPixels'].isna()\n",
    "maskedSamples = train[train['Has Mask'] == True]\n",
    "firstLabel = maskedSamples.groupby('label').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count_df = train.groupby('image').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('Has Mask', ascending=False, inplace=True)\n",
    "train_idx, val_idx = train_test_split(mask_count_df.index, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_resize(img, input_shape):\n",
    "    height, width = input_shape\n",
    "    return cv2.resize(img, (width, height))\n",
    "    \n",
    "def mask2rle(img):\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask = np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape, reshape=None):\n",
    "    depth = len(rles)\n",
    "    if reshape is None:\n",
    "        masks = np.zeros((*input_shape, depth))\n",
    "    else:\n",
    "        masks = np.zeros((*reshape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            if reshape is None:\n",
    "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "            else:\n",
    "                mask = rle2mask(rle, input_shape)\n",
    "                reshaped_mask = np_resize(mask, reshape)\n",
    "                masks[:, :, i] = reshaped_mask\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks, reshape=None):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        if reshape:\n",
    "            mask = mask.astype(np.float32)\n",
    "            mask = np_resize(mask, reshape).astype(np.int64)\n",
    "        \n",
    "        rle = mask2rle(mask)\n",
    "        rles.append(rle)\n",
    "        \n",
    "    return rles\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def post_process(probability, threshold=0.5, min_size=10000):\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros(probability.shape, np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4\n",
    "HEIGHT = 320\n",
    "WIDTH = 480\n",
    "CHANNELS = 3\n",
    "N_CLASSES = train['label'].nunique()\n",
    "ES_PATIENCE = 5\n",
    "RLROP_PATIENCE = 3\n",
    "DECAY_DROP = 0.5\n",
    "BACKBONE = 'resnet34'\n",
    "BASE_PATH = 'input/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path=BASE_PATH,\n",
    "                 batch_size=BATCH_SIZE, dim=(1400, 2100), n_channels=CHANNELS, reshape=None, \n",
    "                 n_classes=N_CLASSES, random_state=seed, shuffle=True, augment=False):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.reshape = reshape\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            \n",
    "            if self.augment:\n",
    "                X, y = self.__augment_batch(X, y)\n",
    "            \n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        if self.reshape is None:\n",
    "            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        else:\n",
    "            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['image'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = cv2.imread(img_path)\n",
    "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img.astype(np.float32) / 255.\n",
    "            \n",
    "            if self.reshape is not None:\n",
    "                img = np_resize(img, self.reshape)\n",
    "            \n",
    "            # Store samples\n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        if self.reshape is None:\n",
    "            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        else:\n",
    "            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['image'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['image'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            \n",
    "            if self.reshape is not None:\n",
    "                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n",
    "            else:\n",
    "                masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __augment_batch(self, img_batch, masks_batch):\n",
    "        for i in range(img_batch.shape[0]):\n",
    "            img_batch[i, ], masks_batch[i, ] = self.__random_transform(img_batch[i, ], masks_batch[i, ])\n",
    "        \n",
    "        return img_batch, masks_batch\n",
    "    \n",
    "    def __random_transform(self, img, masks):\n",
    "        composition = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "                                   albu.VerticalFlip(p=0.5),\n",
    "                                   albu.GridDistortion(p=0.2),\n",
    "                                   albu.ElasticTransform(p=0.2)\n",
    "                                  ])\n",
    "        \n",
    "        composed = composition(image=img, mask=masks)\n",
    "        aug_img = composed['image']\n",
    "        aug_masks = composed['mask']\n",
    "        \n",
    "        return aug_img, aug_masks\n",
    "    \n",
    "train_generator = DataGenerator(\n",
    "                  train_idx, \n",
    "                  df=mask_count_df,\n",
    "                  target_df=train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  reshape=(HEIGHT, WIDTH),\n",
    "                  n_channels=CHANNELS,\n",
    "                  n_classes=N_CLASSES,\n",
    "                  augment=True,\n",
    "                  random_state=seed)\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "                  val_idx, \n",
    "                  df=mask_count_df,\n",
    "                  target_df=train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  reshape=(HEIGHT, WIDTH),\n",
    "                  n_channels=CHANNELS,\n",
    "                  n_classes=N_CLASSES,\n",
    "                  random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "model = sm.Unet(\n",
    "                backbone_name=BACKBONE, \n",
    "                classes=N_CLASSES,\n",
    "                activation='sigmoid',\n",
    "                input_shape=(HEIGHT, WIDTH, CHANNELS)\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n",
    "\n",
    "metric_list = [dice_coef]\n",
    "callback_list = [es, rlrop]\n",
    "optimizer = optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss=bce_dice_loss, metrics=metric_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              epochs=EPOCHS,\n",
    "                              callbacks=callback_list,\n",
    "                              verbose=2).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('re_resnet34.h5')\n",
    "model = load_model('re_resnet34.h5', \n",
    "                   custom_objects={'bce_dice_loss': bce_dice_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "\n",
    "for i in range(0, test.shape[0], 500):\n",
    "    batch_idx = list(range(i, min(test.shape[0], i + 500)))\n",
    "    \n",
    "    test_generator = DataGenerator(\n",
    "                     batch_idx,\n",
    "                     df=test,\n",
    "                     target_df=submission,\n",
    "                     batch_size=1,\n",
    "                     reshape=(HEIGHT, WIDTH),\n",
    "                     dim=(350, 525),\n",
    "                     n_channels=CHANNELS,\n",
    "                     n_classes=N_CLASSES,\n",
    "                     random_state=seed,\n",
    "                     base_path='input/test_images_gray',\n",
    "                     mode='predict',\n",
    "                     shuffle=False)\n",
    "    \n",
    "    batch_pred_masks = model.predict_generator(test_generator)\n",
    "    \n",
    "    for j, b in enumerate(batch_idx):\n",
    "        filename = test['image'].iloc[b]\n",
    "        image_df = submission[submission['image'] == filename].copy()\n",
    "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "        \n",
    "        ### Post procecssing\n",
    "        pred_masks_post = batch_pred_masks[j, ].astype('float32') \n",
    "        for k in range(pred_masks_post.shape[-1]):\n",
    "            pred_mask = pred_masks_post[...,k]\n",
    "\n",
    "            pred_mask, num_predict = post_process(pred_mask)\n",
    "            pred_masks_post[...,k] = pred_mask\n",
    "\n",
    "        pred_rles_post = build_rles(pred_masks_post, reshape=(350, 525))\n",
    "        image_df['EncodedPixels_post'] = pred_rles_post\n",
    "        ###\n",
    "        \n",
    "        pred_rles = build_rles(pred_masks, reshape=(350, 525))        \n",
    "        image_df['EncodedPixels'] = pred_rles\n",
    "        test_df.append(image_df)\n",
    "        \n",
    "sub_df = pd.concat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = sub_df[['Image_Label' ,'EncodedPixels']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_post = sub_df[['Image_Label' ,'EncodedPixels_post']]\n",
    "submission_df_post.columns = ['Image_Label' ,'EncodedPixels']\n",
    "submission_df_post.to_csv('submission_post.csv', index=False)\n",
    "display(submission_df_post.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
